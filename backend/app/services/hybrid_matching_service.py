"""
Hybrid Matching Service - Sistema de Matching H√≠brido com Embeddings

Este servi√ßo implementa um sistema h√≠brido de 3 fases que combina:
1. Busca Sem√¢ntica (Vector Search) - Encontra candidatas por similaridade sem√¢ntica
2. Scoring Determin√≠stico (Unified Scorer) - Pontua candidatas por crit√©rios espec√≠ficos  
3. Refinamento LLM (AI Processor) - An√°lise inteligente das melhores candidatas

Vantagens:
- Redu√ß√£o significativa de custos LLM (menos candidatas para an√°lise)
- Melhor descoberta de matches n√£o √≥bvios (busca sem√¢ntica)
- Mant√©m precis√£o dos crit√©rios espec√≠ficos (CAE codes, etc.)
- Sistema mais robusto e escal√°vel
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy.orm import Session
from app.db.models import Incentive, Company, IncentiveMetadata
from app.services.ai_processor import AIProcessor
from app.services.unified_scorer import UnifiedScorer
from app.services.embedding_service import EmbeddingService
from app.services.vector_database_service import VectorDatabaseService

logger = logging.getLogger(__name__)


class HybridMatchingService:
    """
    Sistema de Matching H√≠brido com Embeddings
    
    Pipeline de 3 fases:
    1. Vector Search: Busca sem√¢ntica ‚Üí Top 50 candidatas
    2. Unified Scoring: Pontua√ß√£o determin√≠stica ‚Üí Top 15 candidatas
    3. LLM Refinement: An√°lise inteligente ‚Üí Top 5 finalistas
    
    Reduz custos LLM em ~70% mantendo qualidade superior.
    """
    
    def __init__(
        self, 
        ai_processor: AIProcessor,
        embedding_service: EmbeddingService,
        vector_db_service: VectorDatabaseService
    ):
        """
        Inicializa o servi√ßo de matching h√≠brido.
        
        Args:
            ai_processor: Processador de IA para an√°lise LLM
            embedding_service: Servi√ßo de gera√ß√£o de embeddings
            vector_db_service: Servi√ßo de base de dados vectorial
        """
        self.ai_processor = ai_processor
        self.embedding_service = embedding_service
        self.vector_db_service = vector_db_service
        self.unified_scorer = UnifiedScorer(ai_processor)
        
        # Configura√ß√µes do pipeline
        self.VECTOR_SEARCH_TOP_K = 50      # Fase 1: Busca sem√¢ntica
        self.UNIFIED_SCORING_TOP_K = 15   # Fase 2: Scoring determin√≠stico
        self.LLM_REFINEMENT_TOP_K = 5     # Fase 3: An√°lise LLM
        
        # Thresholds de qualidade
        self.MIN_SEMANTIC_SIMILARITY = 0.2  # Similaridade m√≠nima para considerar candidata (reduzido)
        self.MIN_UNIFIED_SCORE = 0          # Score m√≠nimo unificado (pode ser 0)
        
        logger.info("‚úÖ Hybrid Matching Service initialized")
        logger.info(f"   Pipeline: Vector({self.VECTOR_SEARCH_TOP_K}) ‚Üí Unified({self.UNIFIED_SCORING_TOP_K}) ‚Üí LLM({self.LLM_REFINEMENT_TOP_K})")
    
    def find_top_matches(
        self, 
        session: Session, 
        incentive_id: str, 
        limit: int = 5,
        use_hybrid: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Encontra as melhores empresas para um incentivo usando sistema h√≠brido.
        
        Args:
            session: Sess√£o da base de dados
            incentive_id: ID do incentivo
            limit: N√∫mero m√°ximo de matches (padr√£o: 5)
            use_hybrid: Se True, usa pipeline h√≠brido; se False, usa sistema original
            
        Returns:
            Lista de matches com scores e raz√µes detalhadas
        """
        logger.info(f"üéØ Finding top {limit} matches for incentive {incentive_id}")
        
        # Obter incentivo
        incentive = session.query(Incentive).filter(
            Incentive.incentive_id == incentive_id
        ).first()
        
        if not incentive:
            logger.error(f"Incentive {incentive_id} not found")
            return []
        
        if use_hybrid:
            return self._find_matches_hybrid(session, incentive, limit)
        else:
            return self._find_matches_original(session, incentive, limit)
    
    def _find_matches_hybrid(
        self, 
        session: Session, 
        incentive: Incentive, 
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        Pipeline h√≠brido de matching com embeddings.
        
        FASE 1: Vector Search ‚Üí Top 50 candidatas sem√¢nticas
        FASE 2: Unified Scoring ‚Üí Top 15 candidatas pontuadas
        FASE 3: LLM Refinement ‚Üí Top 5 finalistas analisadas
        """
        logger.info(f"üîç HYBRID MATCHING for '{incentive.title[:50]}...'")
        
        # ==========================================
        # FASE 1: VECTOR SEARCH (SEM√ÇNTICA)
        # ==========================================
        logger.info("üß† FASE 1: Vector Search (Semantic)...")
        
        semantic_candidates = self.vector_db_service.search_similar_companies(
            incentive=incentive,
            top_k=self.VECTOR_SEARCH_TOP_K,
            min_similarity=self.MIN_SEMANTIC_SIMILARITY
        )
        
        if not semantic_candidates:
            logger.warning("No semantic candidates found, falling back to original system")
            return self._find_matches_original(session, incentive, limit)
        
        logger.info(f"‚úÖ Vector Search: {len(semantic_candidates)} semantic candidates")
        if semantic_candidates:
            logger.info(f"   Top semantic similarity: {semantic_candidates[0][1]:.3f}")
            logger.info(f"   Bottom semantic similarity: {semantic_candidates[-1][1]:.3f}")
        
        # ==========================================
        # FASE 2: UNIFIED SCORING (DETERMIN√çSTICA)
        # ==========================================
        logger.info("üìä FASE 2: Unified Scoring (Deterministic)...")
        
        # Converter candidatas sem√¢nticas para objetos Company
        semantic_companies = [candidate[0] for candidate in semantic_candidates]
        
        # Pontuar candidatas sem√¢nticas
        scored_candidates = []
        for company in semantic_companies:
            score_data = self.unified_scorer.score_company(incentive, company)
            scored_candidates.append({
                'company': company,
                'semantic_similarity': next((c[1] for c in semantic_candidates if c[0].company_id == company.company_id), 0.0),
                'unified_score': score_data['score'],
                'unified_reasons': score_data['details']
            })
        
        # Ordenar por score unificado (maior primeiro)
        scored_candidates.sort(key=lambda x: x['unified_score'], reverse=True)
        
        # Selecionar top candidatas para LLM
        top_candidates = scored_candidates[:self.UNIFIED_SCORING_TOP_K]
        
        logger.info(f"‚úÖ Unified Scoring: {len(top_candidates)} top candidates")
        if top_candidates:
            logger.info(f"   Top unified score: {top_candidates[0]['unified_score']:.1f}")
            logger.info(f"   Bottom unified score: {top_candidates[-1]['unified_score']:.1f}")
        
        # ==========================================
        # FASE 3: LLM REFINEMENT (INTELIGENTE)
        # ==========================================
        logger.info("ü§ñ FASE 3: LLM Refinement (Intelligent)...")
        
        # Preparar dados para LLM
        companies_for_llm = [item['company'] for item in top_candidates]
        
        # Obter metadata do incentivo
        metadata = session.query(IncentiveMetadata).filter(
            IncentiveMetadata.incentive_id == incentive.incentive_id
        ).first()
        
        raw_csv_data = metadata.raw_csv_data if metadata else {}
        
        # An√°lise LLM das top candidatas
        llm_results = self.ai_processor.analyze_batch_match(
            incentive=incentive,
            companies=companies_for_llm,
            raw_csv_data=raw_csv_data,
            select_top_n=limit
        )
        
        logger.info(f"‚úÖ LLM Refinement: {len(llm_results)} final matches")
        
        # ==========================================
        # COMBINAR RESULTADOS
        # ==========================================
        final_matches = []
        
        for llm_result in llm_results:
            # Encontrar dados correspondentes
            company_id = llm_result.get('company_id')
            matching_candidate = next(
                (c for c in top_candidates if str(c['company'].company_id) == company_id), 
                None
            )
            
            if matching_candidate:
                # Combinar scores e raz√µes
                final_match = {
                    'company_id': company_id,
                    'company_name': matching_candidate['company'].company_name,
                    'cae_primary_label': matching_candidate['company'].cae_primary_label,
                    'cae_primary_code': matching_candidate['company'].cae_primary_code,
                    'trade_description_native': matching_candidate['company'].trade_description_native,
                    'website': matching_candidate['company'].website,
                    'company_size': matching_candidate['company'].company_size,
                    'region': matching_candidate['company'].region,
                    
                    # Scores combinados
                    'semantic_similarity': matching_candidate['semantic_similarity'],
                    'unified_score': matching_candidate['unified_score'],
                    'llm_score': llm_result.get('match_score', 0.0),
                    
                    # Raz√µes combinadas
                    'semantic_reasons': [f"Similaridade sem√¢ntica: {matching_candidate['semantic_similarity']:.3f}"],
                    'unified_reasons': matching_candidate['unified_reasons'],
                    'llm_reasons': llm_result.get('reasons', []),
                    
                    # Metadados adicionais
                    'concerns': llm_result.get('concerns', []),
                    'recommendations': llm_result.get('recommendations', []),
                    
                    # Score total combinado (peso: sem√¢ntico 30%, unificado 40%, LLM 30%)
                    'total_score': (
                        matching_candidate['semantic_similarity'] * 0.3 +
                        min(matching_candidate['unified_score'] / 200.0, 1.0) * 0.4 +  # Normalizar unified score
                        llm_result.get('match_score', 0.0) * 0.3
                    )
                }
                
                final_matches.append(final_match)
        
        # Ordenar por score total
        final_matches.sort(key=lambda x: x['total_score'], reverse=True)
        
        logger.info(f"üéØ HYBRID MATCHING COMPLETED: {len(final_matches)} final matches")
        if final_matches:
            logger.info(f"   Top total score: {final_matches[0]['total_score']:.3f}")
            logger.info(f"   Bottom total score: {final_matches[-1]['total_score']:.3f}")
        
        return final_matches
    
    def _find_matches_original(
        self, 
        session: Session, 
        incentive: Incentive, 
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        Sistema original de matching (fallback).
        
        Usa apenas Unified Scoring + LLM Refinement sem busca sem√¢ntica.
        """
        logger.info("üîÑ Using ORIGINAL matching system (fallback)")
        
        # Obter todas as empresas
        all_companies = session.query(Company).all()
        
        # Unified Scoring
        scored_companies = []
        for company in all_companies:
            score_data = self.unified_scorer.score_company(incentive, company)
            scored_companies.append({
                'company': company,
                'unified_score': score_data['score'],
                'unified_reasons': score_data['details']
            })
        
        # Ordenar por score
        scored_companies.sort(key=lambda x: x['unified_score'], reverse=True)
        
        # Selecionar top candidatas
        top_candidates = scored_companies[:15]
        companies_for_llm = [item['company'] for item in top_candidates]
        
        # Obter metadata
        metadata = session.query(IncentiveMetadata).filter(
            IncentiveMetadata.incentive_id == incentive.incentive_id
        ).first()
        
        raw_csv_data = metadata.raw_csv_data if metadata else {}
        
        # LLM Analysis
        llm_results = self.ai_processor.analyze_batch_match(
            incentive=incentive,
            companies=companies_for_llm,
            raw_csv_data=raw_csv_data,
            select_top_n=limit
        )
        
        # Combinar resultados
        final_matches = []
        for llm_result in llm_results:
            company_id = llm_result.get('company_id')
            matching_candidate = next(
                (c for c in top_candidates if str(c['company'].company_id) == company_id), 
                None
            )
            
            if matching_candidate:
                final_match = {
                    'company_id': company_id,
                    'company_name': matching_candidate['company'].company_name,
                    'cae_primary_label': matching_candidate['company'].cae_primary_label,
                    'cae_primary_code': matching_candidate['company'].cae_primary_code,
                    'trade_description_native': matching_candidate['company'].trade_description_native,
                    'website': matching_candidate['company'].website,
                    'company_size': matching_candidate['company'].company_size,
                    'region': matching_candidate['company'].region,
                    
                    'semantic_similarity': 0.0,  # N√£o dispon√≠vel no sistema original
                    'unified_score': matching_candidate['unified_score'],
                    'llm_score': llm_result.get('match_score', 0.0),
                    
                    'semantic_reasons': [],
                    'unified_reasons': matching_candidate['unified_reasons'],
                    'llm_reasons': llm_result.get('reasons', []),
                    
                    'concerns': llm_result.get('concerns', []),
                    'recommendations': llm_result.get('recommendations', []),
                    
                    'total_score': (
                        min(matching_candidate['unified_score'] / 200.0, 1.0) * 0.6 +  # Mais peso para unificado
                        llm_result.get('match_score', 0.0) * 0.4
                    )
                }
                
                final_matches.append(final_match)
        
        final_matches.sort(key=lambda x: x['total_score'], reverse=True)
        
        logger.info(f"üîÑ ORIGINAL MATCHING COMPLETED: {len(final_matches)} matches")
        
        return final_matches
    
    def get_matching_stats(self) -> Dict[str, Any]:
        """
        Retorna estat√≠sticas do sistema de matching.
        
        Returns:
            Dict com estat√≠sticas das diferentes fases
        """
        return {
            "pipeline_config": {
                "vector_search_top_k": self.VECTOR_SEARCH_TOP_K,
                "unified_scoring_top_k": self.UNIFIED_SCORING_TOP_K,
                "llm_refinement_top_k": self.LLM_REFINEMENT_TOP_K,
                "min_semantic_similarity": self.MIN_SEMANTIC_SIMILARITY,
                "min_unified_score": self.MIN_UNIFIED_SCORE
            },
            "vector_database_stats": self.vector_db_service.get_database_stats(),
            "embedding_cache_stats": self.embedding_service.get_cache_stats()
        }
    
    def optimize_pipeline_performance(self) -> Dict[str, Any]:
        """
        Otimiza performance do pipeline ajustando par√¢metros automaticamente.
        
        Returns:
            Dict com otimiza√ß√µes aplicadas
        """
        optimizations = {}
        
        # Obter estat√≠sticas do cache
        cache_stats = self.embedding_service.get_cache_stats()
        
        # Ajustar thresholds baseado na performance
        if cache_stats['hit_rate_percentage'] > 80:
            # Cache est√° funcionando bem, pode ser mais restritivo
            self.MIN_SEMANTIC_SIMILARITY = max(0.35, self.MIN_SEMANTIC_SIMILARITY)
            optimizations['increased_semantic_threshold'] = self.MIN_SEMANTIC_SIMILARITY
        elif cache_stats['hit_rate_percentage'] < 50:
            # Cache n√£o est√° funcionando bem, ser mais permissivo
            self.MIN_SEMANTIC_SIMILARITY = min(0.25, self.MIN_SEMANTIC_SIMILARITY)
            optimizations['decreased_semantic_threshold'] = self.MIN_SEMANTIC_SIMILARITY
        
        # Ajustar tamanhos baseado na qualidade dos resultados
        if self.VECTOR_SEARCH_TOP_K > 30:
            self.VECTOR_SEARCH_TOP_K = 30  # Reduzir para melhor performance
            optimizations['reduced_vector_search_k'] = self.VECTOR_SEARCH_TOP_K
        
        logger.info(f"üîß Pipeline optimizations applied: {optimizations}")
        
        return optimizations
