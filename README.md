# üáµüáπ Sistema de Incentivos P√∫blicos - Portugal

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://www.postgresql.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-orange.svg)](https://openai.com/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)

> **Sistema inteligente de matching entre incentivos p√∫blicos portugueses e empresas**, usando IA h√≠brida (determin√≠stica + LLM) para processar, estruturar e recomendar os incentivos mais adequados para cada empresa.

---

## üìã √çndice

- [üéØ Sobre o Projeto](#-sobre-o-projeto)
- [üèóÔ∏è Arquitetura e Tecnologias](#Ô∏è-arquitetura-e-tecnologias)
- [‚ö° Quick Start](#-quick-start)
- [üöÄ FASE 0: Bootstrap](#-fase-0-bootstrap)
- [üóÑÔ∏è FASE 1: Base de Dados](#Ô∏è-fase-1-base-de-dados)
  - [Arquitetura de 3 Tabelas](#arquitetura-de-3-tabelas)
  - [Pipeline de Processamento](#pipeline-de-processamento)
  - [Sistema H√≠brido (Determin√≠stico + AI)](#sistema-h√≠brido-determin√≠stico--ai)
  - [Otimiza√ß√µes de Custo](#otimiza√ß√µes-de-custo)
  - [Cost Tracking](#cost-tracking)
  - [Scripts de Teste](#scripts-de-teste)
- [üí∞ Custos e Performance](#-custos-e-performance)
- [üìö Estrutura do Projeto](#-estrutura-do-projeto)
- [ü§ù Contribuir](#-contribuir)

---

## üéØ Sobre o Projeto

Este sistema resolve o problema de **matching entre incentivos p√∫blicos portugueses e empresas** atrav√©s de um pipeline inteligente que:

1. **Importa e estrutura** dados heterog√©neos de incentivos 
2. **Processa com modelo h√≠brido (determin√≠stico e IA)** para completar campos em falta e estruturar informa√ß√£o
3. **Faz matching inteligente** entre incentivos e empresas baseado em m√∫ltiplos crit√©rios
4. **Fornece chatbot** para responder quest√µes sobre incentivos



---

## üèóÔ∏è Arquitetura e Tecnologias

### **Stack Tecnol√≥gico**

| Camada | Tecnologia | Prop√≥sito |
|--------|------------|-----------|
| **Backend** | FastAPI + Python 3.11 | API REST ass√≠ncrona e eficiente |
| **Base de Dados** | PostgreSQL 15 | Armazenamento relacional com suporte JSON |
| **ORM** | SQLAlchemy 2.0 | Gest√£o de modelos e queries |
| **Migra√ß√µes** | Alembic | Versionamento de schema |
| **IA/LLM** | OpenAI GPT-4o-mini | Processamento inteligente (custo-eficiente) |
| **Containeriza√ß√£o** | Docker + Docker Compose | Ambiente reproduz√≠vel |
| **Data Processing** | Pandas | Manipula√ß√£o de CSVs e transforma√ß√µes |

### **Arquitetura de Alto N√≠vel**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CSV Data  ‚îÇ (incentivos.csv, companies.csv)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           DATA IMPORT PIPELINE                       ‚îÇ
‚îÇ  ‚Ä¢ Parsing CSV (21 campos heterog√©neos)             ‚îÇ
‚îÇ  ‚Ä¢ Valida√ß√£o e limpeza                              ‚îÇ
‚îÇ  ‚Ä¢ Separa√ß√£o: 10 campos principais + metadata      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         HYBRID PROCESSING SYSTEM                     ‚îÇ
‚îÇ  1Ô∏è‚É£ Deterministic Extraction (all_data JSON)        ‚îÇ
‚îÇ     ‚Üí Extrai datas, or√ßamentos, estrutura          ‚îÇ
‚îÇ  2Ô∏è‚É£ AI Processing (quando deterministic falha)     ‚îÇ
‚îÇ     ‚Üí GPT-4o-mini preenche campos em falta         ‚îÇ
‚îÇ  3Ô∏è‚É£ Cost Optimization                              ‚îÇ
‚îÇ     ‚Üí Prompts adaptados, cache, token limits       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INCENTIVES (10)    ‚îÇ  METADATA (unique)   ‚îÇ   COMPANIES (7)   ‚îÇ
‚îÇ  ‚Ä¢ title             ‚îÇ  ‚Ä¢ raw_csv_data      ‚îÇ  ‚Ä¢ company_name   ‚îÇ
‚îÇ  ‚Ä¢ description       ‚îÇ  ‚Ä¢ all_data          ‚îÇ  ‚Ä¢ cae_code       ‚îÇ
‚îÇ  ‚Ä¢ ai_description    ‚îÇ  ‚Ä¢ ai_proc_status    ‚îÇ  ‚Ä¢ sector         ‚îÇ
‚îÇ  ‚Ä¢ dates (3)         ‚îÇ  ‚Ä¢ fields_by_ai      ‚îÇ  ‚Ä¢ size           ‚îÇ
‚îÇ  ‚Ä¢ total_budget      ‚îÇ  ‚Ä¢ processing_error  ‚îÇ  ‚Ä¢ region         ‚îÇ
‚îÇ  ‚Ä¢ source_link       ‚îÇ  ...                 ‚îÇ  ...              ‚îÇ
‚îÇ  ‚Ä¢ document_urls     ‚îÇ                      ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ö° Quick Start

### **Pr√©-requisitos**
- Docker & Docker Compose
- OpenAI API Key

### **üöÄ Testar o Projeto Completo**

   ```bash
# 1. Configurar API Key
echo "OPENAI_API_KEY=sk-your-key-here" >> .env

# 2. Testar TUDO (dataset completo: 538 incentivos + 21 empresas)
make test  # TODO: Implementar na Fase 2
```

**Custo estimado**: ~$0.15-0.20 (dataset completo)

---

### **üß™ Testar com Sample (Recomendado para Desenvolvimento)**

Para testes r√°pidos e econ√≥micos, usa o **sample de 13 incentivos**:

   ```bash
# Teste completo (reseta BD)
make test-sample
   ```



**Ou teste incremental** (mant√©m BD, s√≥ processa pending):
   ```bash
make test-sample-incremental
```



---

## üöÄ FASE 0: Bootstrap

### **Setup do Ambiente**

O projeto usa **Docker Compose** para garantir ambiente reproduz√≠vel e isolado.

#### **1. Estrutura de Containers**

```yaml
services:
  db:        # PostgreSQL 15
  api:       # FastAPI + Python 3.11
```

#### **2. Inicializa√ß√£o**

   ```bash
# Subir containers
docker compose up -d

# Aplicar migra√ß√µes de BD
docker compose run --rm api alembic upgrade head

# Verificar status
docker compose ps
```

#### **3. Volumes e Persist√™ncia**

```
./data/              ‚Üí CSVs (montado em /data no container)
./backend/           ‚Üí C√≥digo da API
./infra/docker/      ‚Üí Dockerfiles
```

#### **4. Vari√°veis de Ambiente**

Ficheiro `.env`:
```env
OPENAI_API_KEY=sk-...        # Chave OpenAI (obrigat√≥rio)
DATABASE_URL=postgresql://app:password@db:5432/incentives
```

#### **5. Comandos √öteis**

   ```bash
make up      # Subir containers
make down    # Parar e remover containers
make db      # Aceder √† BD PostgreSQL
make api     # Shell dentro do container API
make logs    # Ver logs em tempo real
```

---

## üóÑÔ∏è FASE 1: Base de Dados

### **Objetivo da Fase**

Criar uma **base de dados estruturada e completa** de incentivos p√∫blicos portugueses, processando CSVs heterog√©neos e usando IA (quando necess√°rio) para:
- ‚úÖ Completar campos em falta (datas, or√ßamentos)
- ‚úÖ Estruturar descri√ß√µes em JSON padronizado


---

### **Arquitetura de 3 Tabelas**

Opt√°mos por uma arquitetura **normalizada em 3 tabelas** para maximizar efici√™ncia e manutenibilidade.

#### **üìã Tabela 1: `incentives` (10 campos) - como pedido no enunciado**

**Prop√≥sito**: Dados principais e frequentemente acedidos.

```sql
CREATE TABLE incentives (
    incentive_id      UUID PRIMARY KEY,
    title             VARCHAR(500) NOT NULL,
    description       TEXT,
    ai_description    JSON,              -- ‚≠ê Estruturado pela AI
    document_urls     JSON,
    publication_date  TIMESTAMP,
    start_date        TIMESTAMP,
    end_date          TIMESTAMP,
    total_budget      NUMERIC,
    source_link       VARCHAR(500),
    cae_primary_code  VARCHAR(50)        -- ‚≠ê Inferido pela AI
);
```


#### **üìã Tabela 2: `incentives_metadata` (dados √∫nicos + AI)**

**Prop√≥sito**: Guardar dados originais do CSV + metadados de processamento AI.

**Por que esta tabela?** 
Para seguir a indica√ß√£o do enunciado onde a tabela `incentives` tem **10 campos**, mas o CSV tem **21 campos**, esta tabela serve para preservar todos os dados originais que podem ser relevantes para **matching futuro** (Fase 2), como:
- `all_data` (estrutura completa, calend√°rio, dota√ß√µes)
- `eligibility_criteria` (crit√©rios de elegibilidade)
- `incentive_program` (programa a que pertence)
- `status` (estado do incentivo)

```sql
CREATE TABLE incentives_metadata (
    metadata_id             UUID PRIMARY KEY,
    incentive_id            UUID UNIQUE REFERENCES incentives(incentive_id),
    raw_csv_data            JSON NOT NULL,      -- 13 campos: 9 √∫nicos + ai_description texto + 3 datas raw
    ai_processing_status    VARCHAR(50),        -- pending/processing/completed/failed
    ai_processing_date      TIMESTAMP,
    fields_completed_by_ai  JSON,              -- ['ai_description', 'dates', ...]
    ai_processing_error     TEXT,
    created_at              TIMESTAMP,
    updated_at              TIMESTAMP
);
```

**Detalhe dos 13 campos em `raw_csv_data`**:
- **9 campos √∫nicos** (n√£o existem em `incentives`): `all_data`, `form_info`, `eligibility_criteria`, `regions`, `sectors`, `cae_codes`, `objective`, `scraped_url`, `incentive_id_original`
- **1 campo para AI**: `ai_description` original do CSV em **texto puro** (usado pela AI para converter para JSON estruturado ou como contexto para gerar do zero)
- **3 campos de data/or√ßamento em formato raw** (antes de parsing): `submission_deadline`, `announcement_date`, `total_budget`

**Vantagens**:
- ‚úÖ **Respeita restri√ß√£o** do enunciado (10 campos em `incentives`)
- ‚úÖ **Sem duplica√ß√£o**: `raw_csv_data` guarda campos √∫nicos (n√£o repetidos em `incentives`)
- ‚úÖ **Rastreabilidade**: Sabemos exatamente quais campos foram completados por IA
- ‚úÖ **Controlo de processamento**: Flag `ai_processing_status` evita reprocessamento
- ‚úÖ **Dados para matching**: Campos como `eligibility_criteria` e `all_data` ser√£o usados na Fase 2
- ‚úÖ **Debugging**: `ai_processing_error` guarda erros para an√°lise

#### **üìã Tabela 3: `companies` (7 campos derivados)**

**Prop√≥sito**: Empresas do CSV original (4 campos dispon√≠veis).

```sql
CREATE TABLE companies (
    company_id               UUID PRIMARY KEY,
    company_name             VARCHAR(500) NOT NULL,
    cae_primary_label        VARCHAR(500),      -- Ex: "Software development"
    trade_description_native TEXT,              -- Descri√ß√£o em PT
    website                  VARCHAR(500),
    cae_primary_code         VARCHAR(50),       -- ‚≠ê Inferido pela AI
    company_size             VARCHAR(50),       -- ‚≠ê Inferido pela AI
    region                   VARCHAR(100),      -- ‚≠ê Inferido pela AI
    is_active                BOOLEAN DEFAULT TRUE
);
```

**Campos do CSV**: `company_name`, `cae_primary_label`, `trade_description_native`, `website`

**Campos inferidos pela AI**:
- `cae_primary_code`: C√≥digo CAE num√©rico inferido da descri√ß√£o textual
- `company_size`: Tamanho da empresa (micro/small/medium/large) inferido dos dados dispon√≠veis
- `region`: Regi√£o geogr√°fica inferida do nome e dados da empresa

---

### **Pipeline de Processamento**

#### **Fluxo Completo**

```
CSV ‚Üí Import ‚Üí Deterministic ‚Üí AI (fallback) ‚Üí Structured DB
```

#### **1Ô∏è‚É£ Fase 1: Import (sem custos)**

O `DataImporter` processa 2 CSVs:

**CSV de Incentivos** ‚Üí dividido em 2 tabelas

**CSV de Companies** ‚Üí importado diretamente para tabela `companies`

Ap√≥s o import, o sistema analisa cada incentivo e marca como `ai_processing_status = 'pending'` se estiver em falta:
- `ai_description` em JSON estruturado
- Datas (`publication_date`, `start_date`, `end_date`)
- Or√ßamento (`total_budget`)

**Custo desta fase: $0** (s√≥ parsing e base de dados)

#### **2Ô∏è‚É£ Fase 2: AI Processing (com custos otimizados)**

O `AIProcessor` processa apenas os incentivos marcados como `pending`, usando uma **abordagem h√≠brida** (determin√≠stico primeiro, AI s√≥ quando necess√°rio):

**Para cada incentivo pendente:**

1. **Extra√ß√£o de Datas** (h√≠brido):
   - **Determin√≠stico**: Procura em `all_data->calendario` por `dataPublicacao`, `dataInicio`, `dataFim`
   - **AI Fallback**: Se faltar alguma data, usa LLM para extrair do texto (prompt pequeno, ~300 tokens)
  
2. **Extra√ß√£o de Or√ßamento** (h√≠brido):
   - **Determin√≠stico**: Procura em `all_data->estrutura->dotacoes->valor`
   - **AI Fallback**: Se n√£o encontrar, usa LLM (prompt pequeno, ~200 tokens)

3. **Gera√ß√£o de `ai_description`** (sempre AI, mas otimizado):
   - **Convers√£o** (se campo `ai_description` no CSV tinha texto): Prompt curto pedindo apenas convers√£o de texto para JSON (800 tokens max)
   - **Gera√ß√£o do zero** (se `ai_description` no CSV estava vazio): Prompt completo analisando `all_data` + `eligibility_criteria` (1500 tokens max)
   - **Economia**: Convers√µes custam ~43% menos que gera√ß√µes

#### **3Ô∏è‚É£ Fase 3: Enriquecimento de Dados (infer√™ncia autom√°tica)**

Para maximizar a qualidade do matching, o sistema infere automaticamente campos em falta:

**Para Incentivos:**
- **CAE Code**: Inferido da descri√ß√£o do incentivo usando LLM para identificar setores espec√≠ficos

**Para Empresas:**
- **CAE Code**: Convers√£o de descri√ß√µes textuais (`cae_primary_label`) para c√≥digos num√©ricos usando LLM
- **Regi√£o**: Infer√™ncia da localiza√ß√£o baseada no nome da empresa e dados dispon√≠veis
- **Tamanho**: Classifica√ß√£o autom√°tica do porte da empresa (micro/small/medium/large)

**Estrat√©gias de Otimiza√ß√£o:**
- **Intelligent Fallback**: Mapeamento manual para casos comuns, LLM apenas quando necess√°rio
- **Intelligent Caching**: Reutiliza√ß√£o de respostas para inputs similares
- **Batch Processing**: Processamento em lotes para reduzir custos

---

### **Sistema H√≠brido: Quando usa Determin√≠stico vs AI**

| Campo | M√©todo Determin√≠stico | Quando usa AI | 
|-------|----------------------|---------------|
| **Datas** | Extrai de `all_data->calendario` (chaves fixas) | S√≥ se faltar ap√≥s extra√ß√£o | 
| **Or√ßamento** | Extrai de `all_data->estrutura->dotacoes` | S√≥ se faltar ap√≥s extra√ß√£o | 
| **ai_description** | ‚ùå N√£o aplic√°vel (precisa LLM para estruturar) | **Sempre**, mas com 2 prompts diferentes |
| **CAE Codes** | ‚ùå N√£o aplic√°vel (precisa LLM para inferir) | **Sempre** para incentivos e empresas |
| **Regi√£o** | ‚ùå N√£o aplic√°vel (precisa LLM para inferir) | **Sempre** para empresas |
| **Tamanho** | ‚ùå N√£o aplic√°vel (precisa LLM para inferir) | **Sempre** para empresas | 

**Vantagens do H√≠brido:**
- ‚úÖ **Gr√°tis quando poss√≠vel**
- ‚úÖ **Robusto**: Cobre casos onde dados estruturados est√£o incompletos
- ‚úÖ **Previs√≠vel**: Determin√≠stico d√° sempre o mesmo resultado

---

### **6 Otimiza√ß√µes de Custo Implementadas**

#### **1Ô∏è‚É£ Flag de Processamento (`ai_processing_status`)**

A **otimiza√ß√£o mais fundamental**: Cada incentivo tem um status na tabela `incentives_metadata`:
- `pending`: Precisa ser processado
- `completed`: J√° foi processado com sucesso ‚Üí **nunca reprocessa** (**custo = $0**)
- `failed`: Falhou (pode ser reprocessado manualmente)

**Prote√ß√£o**: Scripts de processamento s√≥ buscam incentivos com status `pending`. Se executares `make test-sample-incremental` duas vezes seguidas, a 2¬™ execu√ß√£o custa **$0** porque todos j√° est√£o `completed`.

**Impacto**: Sem esta flag, reprocessar 538 incentivos por engano custaria ~$0.14 cada vez. Com a flag, **custo = $0** em re-execu√ß√µes.

#### **2Ô∏è‚É£ Prompts Adaptados**

O sistema **detecta automaticamente** se o CSV j√° tinha texto em `ai_description`:
- **Se tinha texto**: Usa prompt curto s√≥ para converter texto‚ÜíJSON (800 tokens m√°x)
- **Se estava vazio**: Usa prompt completo para gerar do zero (1500 tokens m√°x)

**Economia**: Convers√µes custam ~43% menos que gera√ß√µes

#### **3Ô∏è‚É£ Limites de Tokens Calibrados**

Cada opera√ß√£o tem um limite `max_tokens` ajustado ao m√≠nimo necess√°rio (com margem de seguran√ßa):
- `ai_description` (convers√£o): 800 tokens
- `ai_description` (gera√ß√£o): 1500 tokens
- Extra√ß√£o de datas: 300 tokens (s√≥ 3 datas em JSON)
- Extra√ß√£o de or√ßamento: 200 tokens (s√≥ 1 n√∫mero)

#### **4Ô∏è‚É£ Memory Cache**

Antes de chamar a API OpenAI, o sistema calcula um **hash MD5 do prompt completo**:
- **Cache HIT**: Se o prompt j√° foi usado antes nesta sess√£o, retorna o resultado guardado em mem√≥ria (**custo = $0**)
- **Cache MISS**: Se √© novo, chama a API e guarda o resultado no cache

**Caracter√≠sticas**:
- **100% preciso**: S√≥ reutiliza se o prompt for **exatamente** igual (hash MD5)
- **N√£o expira**: Cache dura toda a sess√£o de processamento
- **Transparente**: Aparece no cost tracker como "Cache HIT" ($0)

**Quando ajuda**: Datasets com incentivos duplicados/similares



#### **5Ô∏è‚É£ Enriquecimento Inteligente de Dados**

O sistema infere automaticamente campos em falta usando estrat√©gias otimizadas:

**Intelligent Fallback**: Mapeamento manual para casos comuns (ex: "Software development" ‚Üí CAE 62010)
**Intelligent Caching**: Reutiliza√ß√£o de respostas para inputs similares
**Batch Processing**: Processamento em lotes para reduzir custos de API

**Impacto**: Campos como CAE codes, regi√£o e tamanho s√£o essenciais para matching de qualidade, mas n√£o est√£o nos CSVs originais. O sistema os infere automaticamente com custos m√≠nimos.

---

### **Cost Tracking em Tempo Real**

O sistema implementa **tracking completo de custos** para garantir transpar√™ncia e controlo do or√ßamento.



#### **üìä O que √© tracked**

**N√≠vel de detalhe**: Cada chamada √† API OpenAI √© gravada na base de dados com:
- Tipo de opera√ß√£o (`ai_description_convert`, `extract_dates`, `extract_budget`)
- Modelo usado 
- Tokens consumidos (input, output, total)
- Custo calculado ($0.15/M input, $0.60/M output para gpt-4o-mini)
- Se foi cache HIT ($0) ou MISS (custo real)
- Sucesso/erro

**Visualiza√ß√£o em tempo real**: Durante o processamento, o terminal mostra:
- **Por incentivo**: Custo de cada opera√ß√£o (descri√ß√£o, datas, or√ßamento)
- **Acumulado**: Total gasto at√© agora
- **Resumo final**: Total de chamadas, cache hits/misses, custo m√©dio por incentivo

---

### **Scripts de Teste**

Implement√°mos **2 comandos principais** para testar o sistema com custos m√≠nimos (sample de 13 incentivos e 20 empresas):

#### **üß™ `make test-sample` (Teste Completo)**

**O que faz**:
1. Limpa a base de dados (TRUNCATE em todas as tabelas)
2. Aplica migra√ß√µes (Alembic upgrade head)
3. Importa sample de teste (13 incentivos + 20 empresas)
4. Processa com AI (convers√µes, gera√ß√µes, extra√ß√£o h√≠brida)
5. Mostra custos detalhados

**Quando usar**: Primeira vez, ap√≥s corrigir bugs, ou quando queres come√ßar do zero.

**Custo**: ~$0.003-0.005 (processa todos os 13 incentivos)

#### **üß™ `make test-sample-incremental` (Teste Incremental)**

**O que faz**:
1. Mostra status atual (pending/completed/failed)
2. Processa **APENAS** incentivos marcados como `pending`
3. Mostra custos


**Quando usar**: Reprocessar incentivos que falharam, ou verificar se algo novo precisa processamento.

**Custo**: $0 se tudo j√° est√° processado, ou s√≥ o custo dos incentivos `pending`

#### **üìã Comandos Auxiliares**

- `make show-status`: Ver quantos pending/completed/failed
- `make show-costs`: Ver custos totais guardados na BD
- `make clean-db`: Limpar BD (TRUNCATE)
- `make setup-sample`: S√≥ importar (sem processar AI)
- `make process-ai`: S√≥ processar incentivos pending

---


---

## üéØ FASE 2: Sistema de Matching Inteligente

### **Objetivo da Fase**

Implementar um sistema h√≠brido que identifica automaticamente as 5 empresas mais adequadas para cada incentivo, combinando an√°lise determin√≠stica com intelig√™ncia artificial para maximizar precis√£o e minimizar custos.

---

### **Arquitetura do Sistema**

O sistema implementa uma **abordagem unificada** que combina scoring determin√≠stico com refinamento por LLM:

```
TODAS AS EMPRESAS
‚îÇ
‚îú‚îÄ UNIFIED SCORER (Determin√≠stico)
‚îÇ   ‚îú‚îÄ Analisa CAE codes, setores, regi√£o, tamanho
‚îÇ   ‚îú‚îÄ Atribui scores positivos/negativos
‚îÇ   ‚îú‚îÄ Ordena por relev√¢ncia
‚îÇ   ‚îî‚îÄ Seleciona Top 15 candidatas
‚îÇ
‚îî‚îÄ LLM REFINEMENT (Intelig√™ncia Artificial)
    ‚îú‚îÄ Recebe Top 15 candidatas + crit√©rios do incentivo
    ‚îú‚îÄ Seleciona as 5 melhores com justifica√ß√µes
    ‚îú‚îÄ Valida factualmente as raz√µes
    ‚îî‚îÄ Retorna ranking final otimizado
```



---

### **Unified Scorer: An√°lise Determin√≠stica**

#### **Sistema de Pontua√ß√£o Unificado**

O sistema substitui filtros bin√°rios por um **sistema de pontua√ß√£o cont√≠nuo** que avalia m√∫ltiplos crit√©rios:

**Crit√©rios Positivos:**
- **CAE Code Match**: Pontua√ß√£o alta para c√≥digos CAE exatos ou relacionados
- **Setor Match**: Alinhamento entre atividade da empresa e setores eleg√≠veis
- **Regi√£o Match**: Compatibilidade geogr√°fica com regi√µes eleg√≠veis
- **Tamanho Match**: Adequa√ß√£o do tamanho da empresa aos requisitos

**Crit√©rios Negativos:**
- **Penalties**: Redu√ß√£o de pontos para incompatibilidades √≥bvias
- **Valida√ß√£o**: Verifica√ß√£o autom√°tica de dados inconsistentes

#### **Vantagens da Abordagem Unificada**

- **Flexibilidade**: N√£o elimina empresas prematuramente
- **Granularidade**: Scores permitem ranking preciso
- **Efici√™ncia**: Processamento instant√¢neo sem custos de API
- **Robustez**: Funciona mesmo com dados incompletos





---

### **LLM Refinement: Sele√ß√£o Inteligente**

#### **Processo de Refinamento**

O LLM recebe as 15 melhores candidatas do Unified Scorer e:

1. **Avalia Contextualmente**: Considera nuances que algoritmos determin√≠sticos n√£o captam
2. **Seleciona Top 5**: Escolhe as empresas mais adequadas com justifica√ß√µes


#### **Otimiza√ß√µes de Custo**

**Batch Processing:**
- Uma √∫nica chamada API por incentivo (vs m√∫ltiplas chamadas individuais)
- Processamento de 15 empresas simultaneamente
- Redu√ß√£o dr√°stica de custos comparado com abordagens tradicionais

**Prompt Engineering:**
- Informa√ß√£o essencial apenas (t√≠tulo, setores, CAE codes, requisitos)
- Exclus√£o de campos redundantes ou de baixo impacto
- Estrutura otimizada para respostas JSON consistentes

**Configura√ß√£o Otimizada:**
- `max_tokens=2000`: Suficiente para respostas completas sem truncamento
- Valida√ß√£o p√≥s-LLM para garantir qualidade

#### **Valida√ß√£o e Corre√ß√£o Autom√°tica**

O sistema implementa **valida√ß√£o p√≥s-LLM** que:
- Verifica factualmente as alega√ß√µes do LLM (ex: elegibilidade de CAE codes)
- Corrige scores quando detecta informa√ß√µes incorretas
- Ajusta raz√µes para refletir a realidade dos dados
- Garante que rankings finais s√£o baseados em factos


---


### **Escalabilidade e Performance**

#### **√çndices de Base de Dados**

O sistema utiliza √≠ndices estrat√©gicos para garantir performance com datasets grandes:

```sql
CREATE INDEX idx_companies_cae ON companies(cae_primary_label);
CREATE INDEX idx_companies_name ON companies(company_name);
CREATE INDEX idx_matches_incentive ON incentive_company_matches(incentive_id);
```

#### **Arquitetura de Caching**

- **Memory Cache**: Reutiliza√ß√£o de respostas LLM id√™nticas
- **Intelligent Caching**: Cache baseado em similaridade para inputs parecidos
- **Fallback Mechanisms**: Redu√ß√£o de chamadas LLM desnecess√°rias

---

### **Output e Resultados**

#### **Estrutura de Resposta**

Para cada incentivo, o sistema retorna:

```json
{
  "incentive_id": "uuid",
  "incentive_title": "T√≠tulo do Incentivo",
  "top_5_matches": [
    {
      "company_name": "Nome da Empresa",
      "match_score": 0.85,
      "unified_score": 150,
      "reasons": ["Raz√£o 1", "Raz√£o 2"],
      "ranking_position": 1
    }
  ]
}
```

#### **M√©tricas de Qualidade**

- **Scores Positivos**: Empresas com boa correspond√™ncia
- **Scores Negativos**: Empresas com correspond√™ncia fraca
- **Valida√ß√£o Autom√°tica**: Verifica√ß√£o de consist√™ncia dos resultados
- **Ranking Ordenado**: Empresas ordenadas por relev√¢ncia decrescente

---
### **Scripts de Teste**

#### **üß™ Teste R√°pido (1 incentivo)**

```bash
# Teste com 1 incentivo sample
docker compose run --rm api python -c "
from app.db.database import SessionLocal
from app.services.ai_processor import AIProcessor
from app.services.company_matcher import CompanyMatcher
from app.db.models import Incentive
import os

session = SessionLocal()
ai_processor = AIProcessor(os.getenv('OPENAI_API_KEY'), session)
matcher = CompanyMatcher(ai_processor)

# Pegar primeiro incentivo
incentive = session.query(Incentive).first()
matches = matcher.find_top_matches(session, str(incentive.incentive_id))

print(f'Found {len(matches)} matches')
for i, m in enumerate(matches, 1):
    print(f'{i}. {m[\"company\"].company_name}: {m[\"match_score\"]:.2f}')
"
```

#### **üß™ Teste Completo (todos incentivos)**

```bash
# TODO: Criar script test_matching_visual.py
make test-matching
```

---

### **Comandos Make (TODO)**

```bash
make test-matching              # Testar matching com sample
make test-matching-full         # Processar 538 incentivos
make export-matches-csv         # Exportar resultados para CSV
make compare-optimized-legacy   # Comparar custos otimizado vs legado
```

---

#
---

## üìö Estrutura do Projeto

```
public-incentives/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ alembic/                 # Migra√ß√µes de BD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/            # Hist√≥rico de migra√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                 # Endpoints FastAPI
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_management.py  # POST /import, /process-ai, etc
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py        # SQLAlchemy models (3 tabelas)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py      # Conex√£o e sess√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ data_importer.py          # CSV ‚Üí BD
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ai_processor.py           # Hybrid AI processing
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ cost_tracker.py           # Cost tracking
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ eligibility_filter.py     # FASE 2: Hard constraints
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ deterministic_scorer.py   # FASE 2: Scoring gratuito
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ company_matcher.py        # FASE 2: Matching otimizado
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ test_ai_processing_visual.py  # Teste com visual tracking
‚îÇ       ‚îú‚îÄ‚îÄ create_sample_csvs.py         # Gera samples de teste
‚îÇ       ‚îî‚îÄ‚îÄ validate_import.py            # Valida importa√ß√£o
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ incentives.csv           # Dataset completo (538 linhas)
‚îÇ   ‚îú‚îÄ‚îÄ companies.csv            # Dataset completo (21 linhas)
‚îÇ   ‚îú‚îÄ‚îÄ sample_incentives.csv    # Sample de teste (13 linhas)
‚îÇ   ‚îî‚îÄ‚îÄ sample_companies.csv     # Sample de teste (20 linhas)
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îî‚îÄ‚îÄ docker/
‚îÇ       ‚îú‚îÄ‚îÄ api.Dockerfile       # Imagem da API
‚îÇ       ‚îî‚îÄ‚îÄ init-db.sh           # Inicializa√ß√£o BD
‚îú‚îÄ‚îÄ docker-compose.yml           # Orquestra√ß√£o de containers
‚îú‚îÄ‚îÄ Makefile                     # Comandos √∫teis
‚îî‚îÄ‚îÄ README.md                    # Este ficheiro
```

---


---

## ü§ñ **FASE 3: Chatbot de Incentivos**

### **Sistema Completo Implementado**

O chatbot permite aos utilizadores interagir naturalmente com o sistema atrav√©s de uma interface web moderna:

**Funcionalidades:**
- ‚úÖ **Consultas sobre incentivos**: "Quais incentivos existem para empresas de software?"
- ‚úÖ **Explora√ß√£o de empresas**: "Mostra-me empresas do setor tecnol√≥gico"
- ‚úÖ **An√°lise de correspond√™ncias**: "Que empresas s√£o adequadas para o incentivo X?"
- ‚úÖ **Estat√≠sticas e an√°lises**: "Quantos incentivos temos na base de dados?"
- ‚úÖ **Interface web integrada**: Funciona dentro do container Docker

**Arquitetura:**
- **RAG (Retrieval-Augmented Generation)**: Usa dados estruturados como contexto
- **Query Router inteligente**: Analisa inten√ß√µes e roteia para handlers espec√≠ficos
- **Sistema de contexto**: Mant√©m mem√≥ria da conversa
- **Cache inteligente**: Reduz custos LLM reutilizando respostas similares

### **Como Usar o Chatbot**

```bash
# Iniciar sistema completo
make start-chatbot

# Acessar interface web
# http://localhost:8000/web/

# Testar chatbot
make test-chatbot

# Teste completo do sistema
make test-complete
```

**Exemplos de Perguntas:**
- "Quais incentivos existem para empresas de software?"
- "Mostra-me empresas do setor tecnol√≥gico"
- "Que empresas s√£o adequadas para o incentivo X?"
- "Quantos incentivos temos na base de dados?"
- "Qual o or√ßamento total dispon√≠vel?"

---

### **Roadmap**

- [x] **FASE 0**: Bootstrap (Docker, BD, Migra√ß√µes) ‚úÖ
- [x] **FASE 1**: Base de Dados com AI Processing ‚úÖ
- [x] **FASE 2**: Sistema de Matching Otimizado ‚úÖ
  - [x] Eligibility Pre-Filtering
  - [x] Deterministic Scoring  
  - [x] LLM Refinement
  - [x] CSV Export ‚úÖ
- [x] **FASE 3**: Chatbot para responder quest√µes ‚úÖ
  - [x] ChatbotService com RAG
  - [x] Query Router inteligente
  - [x] Sistema de contexto
  - [x] Interface web integrada
- [x] **FASE 4**: Frontend Web Interface ‚úÖ
  - [x] Interface de chat moderna
  - [x] Integra√ß√£o com API
  - [x] Funciona dentro do container

---

