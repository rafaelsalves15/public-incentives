# ğŸ‡µğŸ‡¹ Sistema de Incentivos PÃºblicos - Portugal

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://www.postgresql.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-orange.svg)](https://openai.com/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)

> **Sistema inteligente de matching entre incentivos pÃºblicos portugueses e empresas**, usando IA hÃ­brida (determinÃ­stica + LLM) para processar, estruturar e recomendar os incentivos mais adequados para cada empresa.

---

## ğŸ“‹ Ãndice

- [ğŸ¯ Sobre o Projeto](#-sobre-o-projeto)
- [ğŸ—ï¸ Arquitetura e Tecnologias](#ï¸-arquitetura-e-tecnologias)
- [âš¡ Quick Start](#-quick-start)
- [ğŸš€ FASE 0: Bootstrap](#-fase-0-bootstrap)
- [ğŸ—„ï¸ FASE 1: Base de Dados](#ï¸-fase-1-base-de-dados)
  - [Arquitetura de 3 Tabelas](#arquitetura-de-3-tabelas)
  - [Pipeline de Processamento](#pipeline-de-processamento)
  - [Sistema HÃ­brido (DeterminÃ­stico + AI)](#sistema-hÃ­brido-determinÃ­stico--ai)
  - [OtimizaÃ§Ãµes de Custo](#otimizaÃ§Ãµes-de-custo)
  - [Cost Tracking](#cost-tracking)
  - [Scripts de Teste](#scripts-de-teste)
- [ğŸ’° Custos e Performance](#-custos-e-performance)
- [ğŸ“š Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸ¤ Contribuir](#-contribuir)

---

## ğŸ¯ Sobre o Projeto

Este sistema resolve o problema de **matching entre incentivos pÃºblicos portugueses e empresas** atravÃ©s de um pipeline inteligente que:

1. **Importa e estrutura** dados heterogÃ©neos de incentivos 
2. **Processa com modelo hÃ­brido (determinÃ­stico e IA)** para completar campos em falta e estruturar informaÃ§Ã£o
3. **Faz matching inteligente** entre incentivos e empresas baseado em mÃºltiplos critÃ©rios
4. **Fornece chatbot** para responder questÃµes sobre incentivos



---

## ğŸ—ï¸ Arquitetura e Tecnologias

### **Stack TecnolÃ³gico**

| Camada | Tecnologia | PropÃ³sito |
|--------|------------|-----------|
| **Backend** | FastAPI + Python 3.11 | API REST assÃ­ncrona e eficiente |
| **Base de Dados** | PostgreSQL 15 | Armazenamento relacional com suporte JSON |
| **ORM** | SQLAlchemy 2.0 | GestÃ£o de modelos e queries |
| **MigraÃ§Ãµes** | Alembic | Versionamento de schema |
| **IA/LLM** | OpenAI GPT-4o-mini | Processamento inteligente (custo-eficiente) |
| **ContainerizaÃ§Ã£o** | Docker + Docker Compose | Ambiente reproduzÃ­vel |
| **Data Processing** | Pandas | ManipulaÃ§Ã£o de CSVs e transformaÃ§Ãµes |

### **Arquitetura de Alto NÃ­vel**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Data  â”‚ (incentivos.csv, companies.csv)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DATA IMPORT PIPELINE                       â”‚
â”‚  â€¢ Parsing CSV (21 campos heterogÃ©neos)             â”‚
â”‚  â€¢ ValidaÃ§Ã£o e limpeza                              â”‚
â”‚  â€¢ SeparaÃ§Ã£o: 10 campos principais + metadata      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HYBRID PROCESSING SYSTEM                     â”‚
â”‚  1ï¸âƒ£ Deterministic Extraction (all_data JSON)        â”‚
â”‚     â†’ Extrai datas, orÃ§amentos, estrutura          â”‚
â”‚  2ï¸âƒ£ AI Processing (quando deterministic falha)     â”‚
â”‚     â†’ GPT-4o-mini preenche campos em falta         â”‚
â”‚  3ï¸âƒ£ Cost Optimization                              â”‚
â”‚     â†’ Prompts adaptados, cache, token limits       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INCENTIVES (10)    â”‚  METADATA (unique)   â”‚   COMPANIES (7)   â”‚
â”‚  â€¢ title             â”‚  â€¢ raw_csv_data      â”‚  â€¢ company_name   â”‚
â”‚  â€¢ description       â”‚  â€¢ all_data          â”‚  â€¢ cae_code       â”‚
â”‚  â€¢ ai_description    â”‚  â€¢ ai_proc_status    â”‚  â€¢ sector         â”‚
â”‚  â€¢ dates (3)         â”‚  â€¢ fields_by_ai      â”‚  â€¢ size           â”‚
â”‚  â€¢ total_budget      â”‚  â€¢ processing_error  â”‚  â€¢ region         â”‚
â”‚  â€¢ source_link       â”‚  ...                 â”‚  ...              â”‚
â”‚  â€¢ document_urls     â”‚                      â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Quick Start

### **PrÃ©-requisitos**
- Docker & Docker Compose
- OpenAI API Key

### **ğŸš€ Testar o Projeto Completo**

   ```bash
# 1. Configurar API Key
echo "OPENAI_API_KEY=sk-your-key-here" >> .env

# 2. Testar TUDO (dataset completo: 538 incentivos + 21 empresas)
make test  # TODO: Implementar na Fase 2
```

**Custo estimado**: ~$0.15-0.20 (dataset completo)

---

### **ğŸ§ª Testar com Sample (Recomendado para Desenvolvimento)**

Para testes rÃ¡pidos e econÃ³micos, usa o **sample de 13 incentivos**:

   ```bash
# Teste completo (reseta BD)
make test-sample
   ```



**Ou teste incremental** (mantÃ©m BD, sÃ³ processa pending):
   ```bash
make test-sample-incremental
```



---

## ğŸš€ FASE 0: Bootstrap

### **Setup do Ambiente**

O projeto usa **Docker Compose** para garantir ambiente reproduzÃ­vel e isolado.

#### **1. Estrutura de Containers**

```yaml
services:
  db:        # PostgreSQL 15
  api:       # FastAPI + Python 3.11
```

#### **2. InicializaÃ§Ã£o**

   ```bash
# Subir containers
docker compose up -d

# Aplicar migraÃ§Ãµes de BD
docker compose run --rm api alembic upgrade head

# Verificar status
docker compose ps
```

#### **3. Volumes e PersistÃªncia**

```
./data/              â†’ CSVs (montado em /data no container)
./backend/           â†’ CÃ³digo da API
./infra/docker/      â†’ Dockerfiles
```

#### **4. VariÃ¡veis de Ambiente**

Ficheiro `.env`:
```env
OPENAI_API_KEY=sk-...        # Chave OpenAI (obrigatÃ³rio)
DATABASE_URL=postgresql://app:password@db:5432/incentives
```

#### **5. Comandos Ãšteis**

   ```bash
make up      # Subir containers
make down    # Parar e remover containers
make db      # Aceder Ã  BD PostgreSQL
make api     # Shell dentro do container API
make logs    # Ver logs em tempo real
```

---

## ğŸ—„ï¸ FASE 1: Base de Dados

### **Objetivo da Fase**

Criar uma **base de dados estruturada e completa** de incentivos pÃºblicos portugueses, processando CSVs heterogÃ©neos e usando IA (quando necessÃ¡rio) para:
- âœ… Completar campos em falta (datas, orÃ§amentos)
- âœ… Estruturar descriÃ§Ãµes em JSON padronizado


---

### **Arquitetura de 3 Tabelas**

OptÃ¡mos por uma arquitetura **normalizada em 3 tabelas** para maximizar eficiÃªncia e manutenibilidade.

#### **ğŸ“‹ Tabela 1: `incentives` (10 campos) - como pedido no enunciado**

**PropÃ³sito**: Dados principais e frequentemente acedidos.

```sql
CREATE TABLE incentives (
    incentive_id      UUID PRIMARY KEY,
    title             VARCHAR(500) NOT NULL,
    description       TEXT,
    ai_description    JSON,              -- â­ Estruturado pela AI
    document_urls     JSON,
    publication_date  TIMESTAMP,
    start_date        TIMESTAMP,
    end_date          TIMESTAMP,
    total_budget      NUMERIC,
    source_link       VARCHAR(500)
);
```


#### **ğŸ“‹ Tabela 2: `incentives_metadata` (dados Ãºnicos + AI)**

**PropÃ³sito**: Guardar dados originais do CSV + metadados de processamento AI.

**Por que esta tabela?** 
Para seguir a indicaÃ§Ã£o do enunciado onde a tabela `incentives` tem **10 campos**, mas o CSV tem **21 campos**, esta tabela serve para preservar todos os dados originais que podem ser relevantes para **matching futuro** (Fase 2), como:
- `all_data` (estrutura completa, calendÃ¡rio, dotaÃ§Ãµes)
- `eligibility_criteria` (critÃ©rios de elegibilidade)
- `incentive_program` (programa a que pertence)
- `status` (estado do incentivo)

```sql
CREATE TABLE incentives_metadata (
    metadata_id             UUID PRIMARY KEY,
    incentive_id            UUID UNIQUE REFERENCES incentives(incentive_id),
    raw_csv_data            JSON NOT NULL,      -- 13 campos: 9 Ãºnicos + ai_description texto + 3 datas raw
    ai_processing_status    VARCHAR(50),        -- pending/processing/completed/failed
    ai_processing_date      TIMESTAMP,
    fields_completed_by_ai  JSON,              -- ['ai_description', 'dates', ...]
    ai_processing_error     TEXT,
    created_at              TIMESTAMP,
    updated_at              TIMESTAMP
);
```

**Detalhe dos 13 campos em `raw_csv_data`**:
- **9 campos Ãºnicos** (nÃ£o existem em `incentives`): `all_data`, `form_info`, `eligibility_criteria`, `regions`, `sectors`, `cae_codes`, `objective`, `scraped_url`, `incentive_id_original`
- **1 campo para AI**: `ai_description` original do CSV em **texto puro** (usado pela AI para converter para JSON estruturado ou como contexto para gerar do zero)
- **3 campos de data/orÃ§amento em formato raw** (antes de parsing): `submission_deadline`, `announcement_date`, `total_budget`

**Vantagens**:
- âœ… **Respeita restriÃ§Ã£o** do enunciado (10 campos em `incentives`)
- âœ… **Sem duplicaÃ§Ã£o**: `raw_csv_data` guarda campos Ãºnicos (nÃ£o repetidos em `incentives`)
- âœ… **Rastreabilidade**: Sabemos exatamente quais campos foram completados por IA
- âœ… **Controlo de processamento**: Flag `ai_processing_status` evita reprocessamento
- âœ… **Dados para matching**: Campos como `eligibility_criteria` e `all_data` serÃ£o usados na Fase 2
- âœ… **Debugging**: `ai_processing_error` guarda erros para anÃ¡lise

#### **ğŸ“‹ Tabela 3: `companies` (7 campos derivados)**

**PropÃ³sito**: Empresas com campos derivados para matching (Fase 2).

```sql
CREATE TABLE companies (
    company_id               UUID PRIMARY KEY,
    company_name             VARCHAR(500) NOT NULL,
    cae_primary_code         VARCHAR(10),       -- Derivado na Fase 2
    cae_primary_label        VARCHAR(500),
    activity_sector          VARCHAR(200),      -- Derivado do CAE
    company_size             VARCHAR(50),       -- micro/small/medium/large
    is_active                BOOLEAN DEFAULT TRUE
);
```

**Nota**: Campos `cae_code`, `sector`, `size` sÃ£o preenchidos na **Fase 2** (Matching).

---

### **Pipeline de Processamento**

#### **Fluxo Completo**

```
CSV â†’ Import â†’ Deterministic â†’ AI (fallback) â†’ Structured DB
```

#### **1ï¸âƒ£ Fase 1: Import (sem custos)**

O `DataImporter` processa 2 CSVs:

**CSV de Incentivos** â†’ dividido em 2 tabelas

**CSV de Companies** â†’ importado diretamente para tabela `companies`

ApÃ³s o import, o sistema analisa cada incentivo e marca como `ai_processing_status = 'pending'` se estiver em falta:
- `ai_description` em JSON estruturado
- Datas (`publication_date`, `start_date`, `end_date`)
- OrÃ§amento (`total_budget`)

**Custo desta fase: $0** (sÃ³ parsing e base de dados)

#### **2ï¸âƒ£ Fase 2: AI Processing (com custos otimizados)**

O `AIProcessor` processa apenas os incentivos marcados como `pending`, usando uma **abordagem hÃ­brida** (determinÃ­stico primeiro, AI sÃ³ quando necessÃ¡rio):

**Para cada incentivo pendente:**

1. **ExtraÃ§Ã£o de Datas** (hÃ­brido):
   - **DeterminÃ­stico**: Procura em `all_data->calendario` por `dataPublicacao`, `dataInicio`, `dataFim`
   - **AI Fallback**: Se faltar alguma data, usa LLM para extrair do texto (prompt pequeno, ~300 tokens)
  
2. **ExtraÃ§Ã£o de OrÃ§amento** (hÃ­brido):
   - **DeterminÃ­stico**: Procura em `all_data->estrutura->dotacoes->valor`
   - **AI Fallback**: Se nÃ£o encontrar, usa LLM (prompt pequeno, ~200 tokens)

3. **GeraÃ§Ã£o de `ai_description`** (sempre AI, mas otimizado):
   - **ConversÃ£o** (se campo `ai_description` no CSV tinha texto): Prompt curto pedindo apenas conversÃ£o de texto para JSON (800 tokens max)
   - **GeraÃ§Ã£o do zero** (se `ai_description` no CSV estava vazio): Prompt completo analisando `all_data` + `eligibility_criteria` (1500 tokens max)
   - **Economia**: ConversÃµes custam ~43% menos que geraÃ§Ãµes

---

### **Sistema HÃ­brido: Quando usa DeterminÃ­stico vs AI**

| Campo | MÃ©todo DeterminÃ­stico | Quando usa AI | 
|-------|----------------------|---------------|
| **Datas** | Extrai de `all_data->calendario` (chaves fixas) | SÃ³ se faltar apÃ³s extraÃ§Ã£o | 
| **OrÃ§amento** | Extrai de `all_data->estrutura->dotacoes` | SÃ³ se faltar apÃ³s extraÃ§Ã£o | 
| **ai_description** | âŒ NÃ£o aplicÃ¡vel (precisa LLM para estruturar) | **Sempre**, mas com 2 prompts diferentes | 

**Vantagens do HÃ­brido:**
- âœ… **GrÃ¡tis quando possÃ­vel**
- âœ… **Robusto**: Cobre casos onde dados estruturados estÃ£o incompletos
- âœ… **PrevisÃ­vel**: DeterminÃ­stico dÃ¡ sempre o mesmo resultado

---

### **5 OtimizaÃ§Ãµes de Custo Implementadas**

#### **1ï¸âƒ£ Flag de Processamento (`ai_processing_status`)**

A **otimizaÃ§Ã£o mais fundamental**: Cada incentivo tem um status na tabela `incentives_metadata`:
- `pending`: Precisa ser processado
- `completed`: JÃ¡ foi processado com sucesso â†’ **nunca reprocessa** (**custo = $0**)
- `failed`: Falhou (pode ser reprocessado manualmente)

**ProteÃ§Ã£o**: Scripts de processamento sÃ³ buscam incentivos com status `pending`. Se executares `make test-sample-incremental` duas vezes seguidas, a 2Âª execuÃ§Ã£o custa **$0** porque todos jÃ¡ estÃ£o `completed`.

**Impacto**: Sem esta flag, reprocessar 538 incentivos por engano custaria ~$0.14 cada vez. Com a flag, **custo = $0** em re-execuÃ§Ãµes.

#### **2ï¸âƒ£ Prompts Adaptados**

O sistema **detecta automaticamente** se o CSV jÃ¡ tinha texto em `ai_description`:
- **Se tinha texto**: Usa prompt curto sÃ³ para converter textoâ†’JSON (800 tokens mÃ¡x)
- **Se estava vazio**: Usa prompt completo para gerar do zero (1500 tokens mÃ¡x)

**Economia**: ConversÃµes custam ~43% menos que geraÃ§Ãµes

#### **3ï¸âƒ£ Limites de Tokens Calibrados**

Cada operaÃ§Ã£o tem um limite `max_tokens` ajustado ao mÃ­nimo necessÃ¡rio (com margem de seguranÃ§a):
- `ai_description` (conversÃ£o): 800 tokens
- `ai_description` (geraÃ§Ã£o): 1500 tokens
- ExtraÃ§Ã£o de datas: 300 tokens (sÃ³ 3 datas em JSON)
- ExtraÃ§Ã£o de orÃ§amento: 200 tokens (sÃ³ 1 nÃºmero)

#### **4ï¸âƒ£ Memory Cache**

Antes de chamar a API OpenAI, o sistema calcula um **hash MD5 do prompt completo**:
- **Cache HIT**: Se o prompt jÃ¡ foi usado antes nesta sessÃ£o, retorna o resultado guardado em memÃ³ria (**custo = $0**)
- **Cache MISS**: Se Ã© novo, chama a API e guarda o resultado no cache

**CaracterÃ­sticas**:
- **100% preciso**: SÃ³ reutiliza se o prompt for **exatamente** igual (hash MD5)
- **NÃ£o expira**: Cache dura toda a sessÃ£o de processamento
- **Transparente**: Aparece no cost tracker como "Cache HIT" ($0)

**Quando ajuda**: Datasets com incentivos duplicados/similares

#### **5ï¸âƒ£ Temperature Baixa (0.1)**

A API OpenAI Ã© chamada com `temperature=0.1` (em vez do padrÃ£o 1.0):
- **Respostas determinÃ­sticas**: Menos "criatividade", mais consistÃªncia
- **Menos tokens desperdiÃ§ados**: AI vai direto ao ponto
- **Melhor para dados estruturados**: JSON sempre bem formatado

---

### **Cost Tracking em Tempo Real**

O sistema implementa **tracking completo de custos** para garantir transparÃªncia e controlo do orÃ§amento.



#### **ğŸ“Š O que Ã© tracked**

**NÃ­vel de detalhe**: Cada chamada Ã  API OpenAI Ã© gravada na base de dados com:
- Tipo de operaÃ§Ã£o (`ai_description_convert`, `extract_dates`, `extract_budget`)
- Modelo usado 
- Tokens consumidos (input, output, total)
- Custo calculado ($0.15/M input, $0.60/M output para gpt-4o-mini)
- Se foi cache HIT ($0) ou MISS (custo real)
- Sucesso/erro

**VisualizaÃ§Ã£o em tempo real**: Durante o processamento, o terminal mostra:
- **Por incentivo**: Custo de cada operaÃ§Ã£o (descriÃ§Ã£o, datas, orÃ§amento)
- **Acumulado**: Total gasto atÃ© agora
- **Resumo final**: Total de chamadas, cache hits/misses, custo mÃ©dio por incentivo

---

### **Scripts de Teste**

ImplementÃ¡mos **2 comandos principais** para testar o sistema com custos mÃ­nimos (sample de 13 incentivos e 20 empresas):

#### **ğŸ§ª `make test-sample` (Teste Completo)**

**O que faz**:
1. Limpa a base de dados (TRUNCATE em todas as tabelas)
2. Aplica migraÃ§Ãµes (Alembic upgrade head)
3. Importa sample de teste (13 incentivos + 20 empresas)
4. Processa com AI (conversÃµes, geraÃ§Ãµes, extraÃ§Ã£o hÃ­brida)
5. Mostra custos detalhados

**Quando usar**: Primeira vez, apÃ³s corrigir bugs, ou quando queres comeÃ§ar do zero.

**Custo**: ~$0.003-0.005 (processa todos os 13 incentivos)

#### **ğŸ§ª `make test-sample-incremental` (Teste Incremental)**

**O que faz**:
1. Mostra status atual (pending/completed/failed)
2. Processa **APENAS** incentivos marcados como `pending`
3. Mostra custos


**Quando usar**: Reprocessar incentivos que falharam, ou verificar se algo novo precisa processamento.

**Custo**: $0 se tudo jÃ¡ estÃ¡ processado, ou sÃ³ o custo dos incentivos `pending`

#### **ğŸ“‹ Comandos Auxiliares**

- `make show-status`: Ver quantos pending/completed/failed
- `make show-costs`: Ver custos totais guardados na BD
- `make clean-db`: Limpar BD (TRUNCATE)
- `make setup-sample`: SÃ³ importar (sem processar AI)
- `make process-ai`: SÃ³ processar incentivos pending

---


#
---

## ğŸ“š Estrutura do Projeto

```
public-incentives/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ alembic/                 # MigraÃ§Ãµes de BD
â”‚   â”‚   â””â”€â”€ versions/            # HistÃ³rico de migraÃ§Ãµes
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/                 # Endpoints FastAPI
â”‚   â”‚   â”‚   â””â”€â”€ data_management.py  # POST /import, /process-ai, etc
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models (3 tabelas)
â”‚   â”‚   â”‚   â””â”€â”€ database.py      # ConexÃ£o e sessÃ£o
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ data_importer.py      # CSV â†’ BD
â”‚   â”‚       â”œâ”€â”€ ai_processor.py       # Hybrid AI processing
â”‚   â”‚       â””â”€â”€ cost_tracker.py       # Cost tracking
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ test_ai_processing_visual.py  # Teste com visual tracking
â”‚       â”œâ”€â”€ create_sample_csvs.py         # Gera samples de teste
â”‚       â””â”€â”€ validate_import.py            # Valida importaÃ§Ã£o
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ incentives.csv           # Dataset completo (538 linhas)
â”‚   â”œâ”€â”€ companies.csv            # Dataset completo (21 linhas)
â”‚   â”œâ”€â”€ sample_incentives.csv    # Sample de teste (13 linhas)
â”‚   â””â”€â”€ sample_companies.csv     # Sample de teste (20 linhas)
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker/
â”‚       â”œâ”€â”€ api.Dockerfile       # Imagem da API
â”‚       â””â”€â”€ init-db.sh           # InicializaÃ§Ã£o BD
â”œâ”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ Makefile                     # Comandos Ãºteis
â””â”€â”€ README.md                    # Este ficheiro
```

---


### **Roadmap Futuro**

- [ ] **FASE 2**: Matching entre incentivos e empresas
- [ ] **FASE 3**: Chatbot para responder questÃµes
- [ ] Frontend em React

---

