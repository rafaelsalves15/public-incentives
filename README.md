# üáµüáπ Sistema de Incentivos P√∫blicos - Portugal

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://www.postgresql.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-orange.svg)](https://openai.com/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)

> **Sistema inteligente de matching entre incentivos p√∫blicos portugueses e empresas**, usando IA h√≠brida (determin√≠stica + LLM) para processar, estruturar e recomendar os incentivos mais adequados para cada empresa.

---

## üìã √çndice

- [üéØ Sobre o Projeto](#-sobre-o-projeto)
- [üèóÔ∏è Arquitetura e Tecnologias](#Ô∏è-arquitetura-e-tecnologias)
- [‚ö° Quick Start](#-quick-start)
- [üöÄ FASE 0: Bootstrap](#-fase-0-bootstrap)
- [üóÑÔ∏è FASE 1: Base de Dados](#Ô∏è-fase-1-base-de-dados)
  - [Arquitetura de 3 Tabelas](#arquitetura-de-3-tabelas)
  - [Pipeline de Processamento](#pipeline-de-processamento)
  - [Sistema H√≠brido (Determin√≠stico + AI)](#sistema-h√≠brido-determin√≠stico--ai)
  - [Otimiza√ß√µes de Custo](#otimiza√ß√µes-de-custo)
  - [Cost Tracking](#cost-tracking)
  - [Scripts de Teste](#scripts-de-teste)
- [üí∞ Custos e Performance](#-custos-e-performance)
- [üìö Estrutura do Projeto](#-estrutura-do-projeto)
- [ü§ù Contribuir](#-contribuir)

---

## üéØ Sobre o Projeto

Este sistema resolve o problema de **matching entre incentivos p√∫blicos portugueses e empresas** atrav√©s de um pipeline inteligente que:

1. **Importa e estrutura** dados heterog√©neos de incentivos 
2. **Processa com modelo h√≠brido (determin√≠stico e IA)** para completar campos em falta e estruturar informa√ß√£o
3. **Faz matching inteligente** entre incentivos e empresas baseado em m√∫ltiplos crit√©rios
4. **Fornece chatbot** para responder quest√µes sobre incentivos



---

## üèóÔ∏è Arquitetura e Tecnologias

### **Stack Tecnol√≥gico**

| Camada | Tecnologia | Prop√≥sito |
|--------|------------|-----------|
| **Backend** | FastAPI + Python 3.11 | API REST ass√≠ncrona e eficiente |
| **Base de Dados** | PostgreSQL 15 | Armazenamento relacional com suporte JSON |
| **ORM** | SQLAlchemy 2.0 | Gest√£o de modelos e queries |
| **Migra√ß√µes** | Alembic | Versionamento de schema |
| **IA/LLM** | OpenAI GPT-4o-mini | Processamento inteligente (custo-eficiente) |
| **Containeriza√ß√£o** | Docker + Docker Compose | Ambiente reproduz√≠vel |
| **Data Processing** | Pandas | Manipula√ß√£o de CSVs e transforma√ß√µes |

### **Arquitetura de Alto N√≠vel**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CSV Data  ‚îÇ (incentivos.csv, companies.csv)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           DATA IMPORT PIPELINE                       ‚îÇ
‚îÇ  ‚Ä¢ Parsing CSV (21 campos heterog√©neos)             ‚îÇ
‚îÇ  ‚Ä¢ Valida√ß√£o e limpeza                              ‚îÇ
‚îÇ  ‚Ä¢ Separa√ß√£o: 10 campos principais + metadata      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         HYBRID PROCESSING SYSTEM                     ‚îÇ
‚îÇ  1Ô∏è‚É£ Deterministic Extraction (all_data JSON)        ‚îÇ
‚îÇ     ‚Üí Extrai datas, or√ßamentos, estrutura          ‚îÇ
‚îÇ  2Ô∏è‚É£ AI Processing (quando deterministic falha)     ‚îÇ
‚îÇ     ‚Üí GPT-4o-mini preenche campos em falta         ‚îÇ
‚îÇ  3Ô∏è‚É£ Cost Optimization                              ‚îÇ
‚îÇ     ‚Üí Prompts adaptados, cache, token limits       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INCENTIVES (10)    ‚îÇ  METADATA (unique)   ‚îÇ   COMPANIES (7)   ‚îÇ
‚îÇ  ‚Ä¢ title             ‚îÇ  ‚Ä¢ raw_csv_data      ‚îÇ  ‚Ä¢ company_name   ‚îÇ
‚îÇ  ‚Ä¢ description       ‚îÇ  ‚Ä¢ all_data          ‚îÇ  ‚Ä¢ cae_code       ‚îÇ
‚îÇ  ‚Ä¢ ai_description    ‚îÇ  ‚Ä¢ ai_proc_status    ‚îÇ  ‚Ä¢ sector         ‚îÇ
‚îÇ  ‚Ä¢ dates (3)         ‚îÇ  ‚Ä¢ fields_by_ai      ‚îÇ  ‚Ä¢ size           ‚îÇ
‚îÇ  ‚Ä¢ total_budget      ‚îÇ  ‚Ä¢ processing_error  ‚îÇ  ‚Ä¢ region         ‚îÇ
‚îÇ  ‚Ä¢ source_link       ‚îÇ  ...                 ‚îÇ  ...              ‚îÇ
‚îÇ  ‚Ä¢ document_urls     ‚îÇ                      ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ö° Quick Start

### **Pr√©-requisitos**
- Docker & Docker Compose
- OpenAI API Key

### **üöÄ Testar o Projeto Completo**

   ```bash
# 1. Configurar API Key
echo "OPENAI_API_KEY=sk-your-key-here" >> .env

# 2. Testar TUDO (dataset completo: 538 incentivos + 21 empresas)
make test  # TODO: Implementar na Fase 2
```

**Custo estimado**: ~$0.15-0.20 (dataset completo)

---

### **üß™ Testar com Sample (Recomendado para Desenvolvimento)**

Para testes r√°pidos e econ√≥micos, usa o **sample de 13 incentivos**:

   ```bash
# Teste completo (reseta BD)
make test-sample
   ```



**Ou teste incremental** (mant√©m BD, s√≥ processa pending):
   ```bash
make test-sample-incremental
```



---

## üöÄ FASE 0: Bootstrap

### **Setup do Ambiente**

O projeto usa **Docker Compose** para garantir ambiente reproduz√≠vel e isolado.

#### **1. Estrutura de Containers**

```yaml
services:
  db:        # PostgreSQL 15
  api:       # FastAPI + Python 3.11
```

#### **2. Inicializa√ß√£o**

   ```bash
# Subir containers
docker compose up -d

# Aplicar migra√ß√µes de BD
docker compose run --rm api alembic upgrade head

# Verificar status
docker compose ps
```

#### **3. Volumes e Persist√™ncia**

```
./data/              ‚Üí CSVs (montado em /data no container)
./backend/           ‚Üí C√≥digo da API
./infra/docker/      ‚Üí Dockerfiles
```

#### **4. Vari√°veis de Ambiente**

Ficheiro `.env`:
```env
OPENAI_API_KEY=sk-...        # Chave OpenAI (obrigat√≥rio)
DATABASE_URL=postgresql://app:password@db:5432/incentives
```

#### **5. Comandos √öteis**

   ```bash
make up      # Subir containers
make down    # Parar e remover containers
make db      # Aceder √† BD PostgreSQL
make api     # Shell dentro do container API
make logs    # Ver logs em tempo real
```

---

## üóÑÔ∏è FASE 1: Base de Dados

### **Objetivo da Fase**

Criar uma **base de dados estruturada e completa** de incentivos p√∫blicos portugueses, processando CSVs heterog√©neos e usando IA (quando necess√°rio) para:
- ‚úÖ Completar campos em falta (datas, or√ßamentos)
- ‚úÖ Estruturar descri√ß√µes em JSON padronizado


---

### **Arquitetura de 3 Tabelas**

Opt√°mos por uma arquitetura **normalizada em 3 tabelas** para maximizar efici√™ncia e manutenibilidade.

#### **üìã Tabela 1: `incentives` (10 campos) - como pedido no enunciado**

**Prop√≥sito**: Dados principais e frequentemente acedidos.

```sql
CREATE TABLE incentives (
    incentive_id      UUID PRIMARY KEY,
    title             VARCHAR(500) NOT NULL,
    description       TEXT,
    ai_description    JSON,              -- ‚≠ê Estruturado pela AI
    document_urls     JSON,
    publication_date  TIMESTAMP,
    start_date        TIMESTAMP,
    end_date          TIMESTAMP,
    total_budget      NUMERIC,
    source_link       VARCHAR(500)
);
```


#### **üìã Tabela 2: `incentives_metadata` (dados √∫nicos + AI)**

**Prop√≥sito**: Guardar dados originais do CSV + metadados de processamento AI.

**Por que esta tabela?** 
Para seguir a indica√ß√£o do enunciado onde a tabela `incentives` tem **10 campos**, mas o CSV tem **21 campos**, esta tabela serve para preservar todos os dados originais que podem ser relevantes para **matching futuro** (Fase 2), como:
- `all_data` (estrutura completa, calend√°rio, dota√ß√µes)
- `eligibility_criteria` (crit√©rios de elegibilidade)
- `incentive_program` (programa a que pertence)
- `status` (estado do incentivo)

```sql
CREATE TABLE incentives_metadata (
    metadata_id             UUID PRIMARY KEY,
    incentive_id            UUID UNIQUE REFERENCES incentives(incentive_id),
    raw_csv_data            JSON NOT NULL,      -- 13 campos: 9 √∫nicos + ai_description texto + 3 datas raw
    ai_processing_status    VARCHAR(50),        -- pending/processing/completed/failed
    ai_processing_date      TIMESTAMP,
    fields_completed_by_ai  JSON,              -- ['ai_description', 'dates', ...]
    ai_processing_error     TEXT,
    created_at              TIMESTAMP,
    updated_at              TIMESTAMP
);
```

**Detalhe dos 13 campos em `raw_csv_data`**:
- **9 campos √∫nicos** (n√£o existem em `incentives`): `all_data`, `form_info`, `eligibility_criteria`, `regions`, `sectors`, `cae_codes`, `objective`, `scraped_url`, `incentive_id_original`
- **1 campo para AI**: `ai_description` original do CSV em **texto puro** (usado pela AI para converter para JSON estruturado ou como contexto para gerar do zero)
- **3 campos de data/or√ßamento em formato raw** (antes de parsing): `submission_deadline`, `announcement_date`, `total_budget`

**Vantagens**:
- ‚úÖ **Respeita restri√ß√£o** do enunciado (10 campos em `incentives`)
- ‚úÖ **Sem duplica√ß√£o**: `raw_csv_data` guarda campos √∫nicos (n√£o repetidos em `incentives`)
- ‚úÖ **Rastreabilidade**: Sabemos exatamente quais campos foram completados por IA
- ‚úÖ **Controlo de processamento**: Flag `ai_processing_status` evita reprocessamento
- ‚úÖ **Dados para matching**: Campos como `eligibility_criteria` e `all_data` ser√£o usados na Fase 2
- ‚úÖ **Debugging**: `ai_processing_error` guarda erros para an√°lise

#### **üìã Tabela 3: `companies` (7 campos derivados)**

**Prop√≥sito**: Empresas com campos derivados para matching (Fase 2).

```sql
CREATE TABLE companies (
    company_id               UUID PRIMARY KEY,
    company_name             VARCHAR(500) NOT NULL,
    cae_primary_code         VARCHAR(10),       -- Derivado na Fase 2
    cae_primary_label        VARCHAR(500),
    activity_sector          VARCHAR(200),      -- Derivado do CAE
    company_size             VARCHAR(50),       -- micro/small/medium/large
    is_active                BOOLEAN DEFAULT TRUE
);
```

**Nota**: Campos `cae_code`, `sector`, `size` s√£o preenchidos na **Fase 2** (Matching).

---

### **Pipeline de Processamento**

#### **Fluxo Completo**

```
CSV ‚Üí Import ‚Üí Deterministic ‚Üí AI (fallback) ‚Üí Structured DB
```

#### **1Ô∏è‚É£ Fase 1: Import (sem custos)**

O `DataImporter` processa 2 CSVs:

**CSV de Incentivos** ‚Üí dividido em 2 tabelas

**CSV de Companies** ‚Üí importado diretamente para tabela `companies`

Ap√≥s o import, o sistema analisa cada incentivo e marca como `ai_processing_status = 'pending'` se estiver em falta:
- `ai_description` em JSON estruturado
- Datas (`publication_date`, `start_date`, `end_date`)
- Or√ßamento (`total_budget`)

**Custo desta fase: $0** (s√≥ parsing e base de dados)

#### **2Ô∏è‚É£ Fase 2: AI Processing (com custos otimizados)**

O `AIProcessor` processa apenas os incentivos marcados como `pending`, usando uma **abordagem h√≠brida** (determin√≠stico primeiro, AI s√≥ quando necess√°rio):

**Para cada incentivo pendente:**

1. **Extra√ß√£o de Datas** (h√≠brido):
   - **Determin√≠stico**: Procura em `all_data->calendario` por `dataPublicacao`, `dataInicio`, `dataFim`
   - **AI Fallback**: Se faltar alguma data, usa LLM para extrair do texto (prompt pequeno, ~300 tokens)
  
2. **Extra√ß√£o de Or√ßamento** (h√≠brido):
   - **Determin√≠stico**: Procura em `all_data->estrutura->dotacoes->valor`
   - **AI Fallback**: Se n√£o encontrar, usa LLM (prompt pequeno, ~200 tokens)

3. **Gera√ß√£o de `ai_description`** (sempre AI, mas otimizado):
   - **Convers√£o** (se campo `ai_description` no CSV tinha texto): Prompt curto pedindo apenas convers√£o de texto para JSON (800 tokens max)
   - **Gera√ß√£o do zero** (se `ai_description` no CSV estava vazio): Prompt completo analisando `all_data` + `eligibility_criteria` (1500 tokens max)
   - **Economia**: Convers√µes custam ~43% menos que gera√ß√µes

---

### **Sistema H√≠brido: Quando usa Determin√≠stico vs AI**

| Campo | M√©todo Determin√≠stico | Quando usa AI | 
|-------|----------------------|---------------|
| **Datas** | Extrai de `all_data->calendario` (chaves fixas) | S√≥ se faltar ap√≥s extra√ß√£o | 
| **Or√ßamento** | Extrai de `all_data->estrutura->dotacoes` | S√≥ se faltar ap√≥s extra√ß√£o | 
| **ai_description** | ‚ùå N√£o aplic√°vel (precisa LLM para estruturar) | **Sempre**, mas com 2 prompts diferentes | 

**Vantagens do H√≠brido:**
- ‚úÖ **Gr√°tis quando poss√≠vel**
- ‚úÖ **Robusto**: Cobre casos onde dados estruturados est√£o incompletos
- ‚úÖ **Previs√≠vel**: Determin√≠stico d√° sempre o mesmo resultado

---

### **5 Otimiza√ß√µes de Custo Implementadas**

#### **1Ô∏è‚É£ Flag de Processamento (`ai_processing_status`)**

A **otimiza√ß√£o mais fundamental**: Cada incentivo tem um status na tabela `incentives_metadata`:
- `pending`: Precisa ser processado
- `completed`: J√° foi processado com sucesso ‚Üí **nunca reprocessa** (**custo = $0**)
- `failed`: Falhou (pode ser reprocessado manualmente)

**Prote√ß√£o**: Scripts de processamento s√≥ buscam incentivos com status `pending`. Se executares `make test-sample-incremental` duas vezes seguidas, a 2¬™ execu√ß√£o custa **$0** porque todos j√° est√£o `completed`.

**Impacto**: Sem esta flag, reprocessar 538 incentivos por engano custaria ~$0.14 cada vez. Com a flag, **custo = $0** em re-execu√ß√µes.

#### **2Ô∏è‚É£ Prompts Adaptados**

O sistema **detecta automaticamente** se o CSV j√° tinha texto em `ai_description`:
- **Se tinha texto**: Usa prompt curto s√≥ para converter texto‚ÜíJSON (800 tokens m√°x)
- **Se estava vazio**: Usa prompt completo para gerar do zero (1500 tokens m√°x)

**Economia**: Convers√µes custam ~43% menos que gera√ß√µes

#### **3Ô∏è‚É£ Limites de Tokens Calibrados**

Cada opera√ß√£o tem um limite `max_tokens` ajustado ao m√≠nimo necess√°rio (com margem de seguran√ßa):
- `ai_description` (convers√£o): 800 tokens
- `ai_description` (gera√ß√£o): 1500 tokens
- Extra√ß√£o de datas: 300 tokens (s√≥ 3 datas em JSON)
- Extra√ß√£o de or√ßamento: 200 tokens (s√≥ 1 n√∫mero)

#### **4Ô∏è‚É£ Memory Cache**

Antes de chamar a API OpenAI, o sistema calcula um **hash MD5 do prompt completo**:
- **Cache HIT**: Se o prompt j√° foi usado antes nesta sess√£o, retorna o resultado guardado em mem√≥ria (**custo = $0**)
- **Cache MISS**: Se √© novo, chama a API e guarda o resultado no cache

**Caracter√≠sticas**:
- **100% preciso**: S√≥ reutiliza se o prompt for **exatamente** igual (hash MD5)
- **N√£o expira**: Cache dura toda a sess√£o de processamento
- **Transparente**: Aparece no cost tracker como "Cache HIT" ($0)

**Quando ajuda**: Datasets com incentivos duplicados/similares

#### **5Ô∏è‚É£ Temperature Baixa (0.1)**

A API OpenAI √© chamada com `temperature=0.1` (em vez do padr√£o 1.0):
- **Respostas determin√≠sticas**: Menos "criatividade", mais consist√™ncia
- **Menos tokens desperdi√ßados**: AI vai direto ao ponto
- **Melhor para dados estruturados**: JSON sempre bem formatado

---

### **Cost Tracking em Tempo Real**

O sistema implementa **tracking completo de custos** para garantir transpar√™ncia e controlo do or√ßamento.



#### **üìä O que √© tracked**

**N√≠vel de detalhe**: Cada chamada √† API OpenAI √© gravada na base de dados com:
- Tipo de opera√ß√£o (`ai_description_convert`, `extract_dates`, `extract_budget`)
- Modelo usado 
- Tokens consumidos (input, output, total)
- Custo calculado ($0.15/M input, $0.60/M output para gpt-4o-mini)
- Se foi cache HIT ($0) ou MISS (custo real)
- Sucesso/erro

**Visualiza√ß√£o em tempo real**: Durante o processamento, o terminal mostra:
- **Por incentivo**: Custo de cada opera√ß√£o (descri√ß√£o, datas, or√ßamento)
- **Acumulado**: Total gasto at√© agora
- **Resumo final**: Total de chamadas, cache hits/misses, custo m√©dio por incentivo

---

### **Scripts de Teste**

Implement√°mos **2 comandos principais** para testar o sistema com custos m√≠nimos (sample de 13 incentivos e 20 empresas):

#### **üß™ `make test-sample` (Teste Completo)**

**O que faz**:
1. Limpa a base de dados (TRUNCATE em todas as tabelas)
2. Aplica migra√ß√µes (Alembic upgrade head)
3. Importa sample de teste (13 incentivos + 20 empresas)
4. Processa com AI (convers√µes, gera√ß√µes, extra√ß√£o h√≠brida)
5. Mostra custos detalhados

**Quando usar**: Primeira vez, ap√≥s corrigir bugs, ou quando queres come√ßar do zero.

**Custo**: ~$0.003-0.005 (processa todos os 13 incentivos)

#### **üß™ `make test-sample-incremental` (Teste Incremental)**

**O que faz**:
1. Mostra status atual (pending/completed/failed)
2. Processa **APENAS** incentivos marcados como `pending`
3. Mostra custos


**Quando usar**: Reprocessar incentivos que falharam, ou verificar se algo novo precisa processamento.

**Custo**: $0 se tudo j√° est√° processado, ou s√≥ o custo dos incentivos `pending`

#### **üìã Comandos Auxiliares**

- `make show-status`: Ver quantos pending/completed/failed
- `make show-costs`: Ver custos totais guardados na BD
- `make clean-db`: Limpar BD (TRUNCATE)
- `make setup-sample`: S√≥ importar (sem processar AI)
- `make process-ai`: S√≥ processar incentivos pending

---


#
---

## üìö Estrutura do Projeto

```
public-incentives/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ alembic/                 # Migra√ß√µes de BD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/            # Hist√≥rico de migra√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                 # Endpoints FastAPI
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_management.py  # POST /import, /process-ai, etc
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py        # SQLAlchemy models (3 tabelas)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py      # Conex√£o e sess√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ data_importer.py      # CSV ‚Üí BD
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ai_processor.py       # Hybrid AI processing
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ cost_tracker.py       # Cost tracking
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ test_ai_processing_visual.py  # Teste com visual tracking
‚îÇ       ‚îú‚îÄ‚îÄ create_sample_csvs.py         # Gera samples de teste
‚îÇ       ‚îî‚îÄ‚îÄ validate_import.py            # Valida importa√ß√£o
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ incentives.csv           # Dataset completo (538 linhas)
‚îÇ   ‚îú‚îÄ‚îÄ companies.csv            # Dataset completo (21 linhas)
‚îÇ   ‚îú‚îÄ‚îÄ sample_incentives.csv    # Sample de teste (13 linhas)
‚îÇ   ‚îî‚îÄ‚îÄ sample_companies.csv     # Sample de teste (20 linhas)
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îî‚îÄ‚îÄ docker/
‚îÇ       ‚îú‚îÄ‚îÄ api.Dockerfile       # Imagem da API
‚îÇ       ‚îî‚îÄ‚îÄ init-db.sh           # Inicializa√ß√£o BD
‚îú‚îÄ‚îÄ docker-compose.yml           # Orquestra√ß√£o de containers
‚îú‚îÄ‚îÄ Makefile                     # Comandos √∫teis
‚îî‚îÄ‚îÄ README.md                    # Este ficheiro
```

---


### **Roadmap Futuro**

- [ ] **FASE 2**: Matching entre incentivos e empresas
- [ ] **FASE 3**: Chatbot para responder quest√µes
- [ ] Frontend em React

---

